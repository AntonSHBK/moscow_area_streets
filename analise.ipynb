{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to Pandas DataFrame\n",
    "Для того что бы быстрее взаимодействовать с данными переводим их в DataFrame а также сохраняем в бинарном виде через модуль Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(data, file:str):\n",
    "    with open(file, 'wb') as data_file:\n",
    "        pickle.dump(data, data_file)\n",
    "\n",
    "def load_pickle(file):\n",
    "    with open(file, 'rb') as data_file:\n",
    "        return pickle.load(data_file)\n",
    "    \n",
    "def save_to_csv(data, file_name):\n",
    "    data.to_csv(file_name, encoding='utf-16', sep=';', index=False)\n",
    "            \n",
    "def save_to_xlsx(data, file_name):\n",
    "    label = list(data[0].keys())\n",
    "    pd_frame = pd.DataFrame(\n",
    "        data,\n",
    "        columns=label\n",
    "    )\n",
    "    pd_frame.to_excel(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIND_REGION = '50'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dbfread import DBF\n",
    "\n",
    "# ALTNAMES = DBF('data/ALTNAMES.dbf')\n",
    "# DOMA = DBF('data/DOMA.dbf')\n",
    "# KLADR = DBF('data/KLADR.dbf')\n",
    "# SOCRBASE = DBF('data/SOCRBASE.dbf')\n",
    "# STREET = DBF('data/STREET.dbf')\n",
    "# NAMEMAP = DBF('data/NAMEMAP.dbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kladr = pd.DataFrame(iter(KLADR))\n",
    "# streets = pd.DataFrame(iter(STREET))\n",
    "# homes = pd.DataFrame(iter(DOMA))\n",
    "# short_names = pd.DataFrame(iter(SOCRBASE))\n",
    "# altnames = pd.DataFrame(iter(ALTNAMES))\n",
    "# namemap = pd.DataFrame(iter(NAMEMAP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# regexp_1 = '^'+FIND_REGION+'\\d*00$'\n",
    "# regexp_2 = '^'+FIND_REGION+'\\d*'\n",
    "\n",
    "# first_kladr = kladr[kladr['CODE'].str.contains(regexp_1)]\n",
    "# first_streets = streets[streets['CODE'].str.contains(regexp_1)]\n",
    "# first_homes = homes[homes['CODE'].str.contains(regexp_2)]\n",
    "# first_altnames = altnames[altnames['NEWCODE'].str.contains(regexp_2)]\n",
    "# first_namemap = namemap[namemap['CODE'].str.contains(regexp_2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_pickle(first_kladr, 'data/'+FIND_REGION+'_region_kladr.pkl')\n",
    "# save_pickle(first_streets, 'data/'+FIND_REGION+'_region_streets.pkl')\n",
    "# save_pickle(first_homes, 'data/'+FIND_REGION+'_region_homes.pkl')\n",
    "# save_pickle(first_altnames, 'data/'+FIND_REGION+'_region_altnames.pkl')\n",
    "# save_pickle(first_namemap, 'data/'+FIND_REGION+'_region_namemap.pkl')\n",
    "# save_pickle(short_names, 'data/short_names.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "kladr:pd.DataFrame = load_pickle('data/'+FIND_REGION+'_region_kladr.pkl')\n",
    "streets:pd.DataFrame = load_pickle('data/'+FIND_REGION+'_region_streets.pkl')\n",
    "homes:pd.DataFrame = load_pickle('data/'+FIND_REGION+'_region_homes.pkl')\n",
    "short_names:pd.DataFrame = load_pickle('data/short_names.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбираем только тестовые улицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_streets = streets[2000:2010]\n",
    "# test_streets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import NaN\n",
    "\n",
    "\n",
    "class KladrFinder():\n",
    "    def __init__(\n",
    "            self,\n",
    "            kladr: pd.DataFrame,\n",
    "            streets: pd.DataFrame,\n",
    "            homes: pd.DataFrame,\n",
    "            short_names: pd.DataFrame\n",
    "        ) -> None:\n",
    "        self.kladr = kladr\n",
    "        self.streets =streets\n",
    "        self.homes = homes\n",
    "        self.short_names = short_names\n",
    "        \n",
    "        street_df_columns =  [\n",
    "            'level_1_name',\n",
    "            'level_1_short_name',\n",
    "            'level_1_code',\n",
    "            \n",
    "            'level_2_name',\n",
    "            'level_2_short_name',\n",
    "            'level_2_code',\n",
    "            \n",
    "            'level_3_name',\n",
    "            'level_3_short_name',\n",
    "            'level_3_code',\n",
    "            \n",
    "            'level_4_name',\n",
    "            'level_4_short_name',\n",
    "            'level_4_code',\n",
    "            \n",
    "            'level_5_name',\n",
    "            'level_5_short_name',\n",
    "            'level_5_code',\n",
    "            \n",
    "            'level_6_name',\n",
    "            'level_6_short_name',\n",
    "        ] \n",
    "        self.streets_df = pd.DataFrame(columns=street_df_columns, )\n",
    "         \n",
    "        self.streets_list_dict = []\n",
    "         \n",
    "        self.anomaly = []   \n",
    "    \n",
    "    def add_anomaly(self, message):\n",
    "        self.anomaly.append(message)\n",
    "    \n",
    "\n",
    "    def find_level_1(self, code):\n",
    "        new_code = code[:2]+('0'*11)\n",
    "        return self.find_kladr_for_code(new_code)\n",
    "    \n",
    "    def find_level_2(self, code):\n",
    "        if (code[2:5] == '000'):\n",
    "            return None\n",
    "        new_code = code[:5]+('0'*8)\n",
    "        return self.find_kladr_for_code(new_code)\n",
    "    \n",
    "    def find_level_3(self, code):\n",
    "        if (code[5:8] == '000'):\n",
    "            return None       \n",
    "        new_code = code[:8]+('0'*5)\n",
    "        return self.find_kladr_for_code(new_code)\n",
    "    \n",
    "    def find_level_4(self, code:str):\n",
    "        if (code[8:11] == '000'):\n",
    "            return None       \n",
    "        new_code = code[:11]+('0'*2)\n",
    "        return self.find_kladr_for_code(new_code)\n",
    "        \n",
    "    def find_level_6(self, code):\n",
    "        return self.find_home_for_code(code)   \n",
    "    \n",
    "    def find_kladr_for_code(self, code:str):\n",
    "        kladr_list = self.kladr[self.kladr['CODE'].str.contains(code)]\n",
    "        kladr_list = kladr_list.reset_index(drop=True)\n",
    "        return kladr_list\n",
    "\n",
    "    def find_home_for_code(self, code:str):\n",
    "        regexp = r'^'+code+'\\d*'\n",
    "        homes_df = self.homes[self.homes['CODE'].str.contains(regexp)]\n",
    "        names = []\n",
    "        short_name = 'ДОМ'        \n",
    "        for index, row in homes_df.iterrows():\n",
    "            temp = row['NAME'].split(',')\n",
    "            for i in temp:\n",
    "                names.append(i)\n",
    "        return {\n",
    "            'level_6_name': names,\n",
    "            'level_6_short_name': short_name\n",
    "        }\n",
    "    \n",
    "    def yandex_mask(\n",
    "            self,\n",
    "            l_1_name, l_1_short,\n",
    "            l_2_name, l_2_short,\n",
    "            l_3_name, l_3_short,\n",
    "            l_4_name, l_4_short,\n",
    "            l_5_name, l_5_short,\n",
    "            l_6_name, l_6_short                             \n",
    "        ):\n",
    "        return ''\n",
    "    \n",
    "    def create_yandex_data(self):       \n",
    "        short_data_list = [] \n",
    "        long_data_list = []\n",
    "        for index in self.streets_df.index:\n",
    "            homes = self.streets_df['level_6_name'][index]\n",
    "            for home in homes:\n",
    "                text_levels = []\n",
    "                text_levels.append(' '.join([self.streets_df['level_1_name'][index], self.streets_df['level_1_short_name'][index]]))\n",
    "                if 'level_2_name' in self.streets_df.columns:\n",
    "                    if self.streets_df['level_2_name'][index] is not NaN:\n",
    "                        level_2 = ' '.join([str(self.streets_df['level_2_name'][index]), str(self.streets_df['level_2_short_name'][index])])\n",
    "                if 'level_3_name' in self.streets_df.columns:\n",
    "                    if self.streets_df['level_3_name'][index] is not NaN:\n",
    "                        text_levels.append(' '.join([str(self.streets_df['level_3_short_name'][index]), str(self.streets_df['level_3_name'][index])]))\n",
    "                if 'level_4_name' in self.streets_df.columns:\n",
    "                    if self.streets_df['level_4_name'][index] is not NaN:\n",
    "                        text_levels.append(' '.join([str(self.streets_df['level_4_short_name'][index]), str(self.streets_df['level_4_name'][index])]))\n",
    "                if 'level_5_name' in self.streets_df.columns:\n",
    "                    if self.streets_df['level_5_name'][index] is not NaN:\n",
    "                        text_levels.append(' '.join([str(self.streets_df['level_5_name'][index]), str(self.streets_df['level_5_short_name'][index])]))\n",
    "                row_dict_short = ', '.join(text_levels)\n",
    "                row_dict_short = ' '.join([row_dict_short, home])\n",
    "                short_data_list.append(row_dict_short)\n",
    "        self.yandex_addresses = pd.DataFrame(short_data_list, columns=['name'])\n",
    "    \n",
    "    def calculate(self):\n",
    "        cnt = 0\n",
    "        for index, row in self.streets.iterrows():\n",
    "            cnt +=1\n",
    "            if cnt % 100 == 0:\n",
    "                print('calculate', cnt/len(self.streets)*100, '%')\n",
    "            row_dict = {}\n",
    "            try:\n",
    "                row_dict.update({\n",
    "                    'level_5_name': row['NAME'],\n",
    "                    'level_5_short_name': row['SOCR'],\n",
    "                    'level_5_code': row['CODE'],\n",
    "                })\n",
    "                code = row['CODE'][0:-6]+row['CODE'][-2:]\n",
    "                locality = self.find_level_4(code)\n",
    "                if locality is not None:\n",
    "                    row_dict.update({\n",
    "                        'level_4_name': locality['NAME'][0],\n",
    "                        'level_4_short_name': locality['SOCR'][0],\n",
    "                        'level_4_code': locality['CODE'][0],\n",
    "                    })\n",
    "                city = self.find_level_3(code)\n",
    "                if city is not None:\n",
    "                    row_dict.update({\n",
    "                        'level_3_name': city['NAME'][0],\n",
    "                        'level_3_short_name': city['SOCR'][0],\n",
    "                        'level_3_code': city['CODE'][0],\n",
    "                    })\n",
    "                district = self.find_level_2(code)\n",
    "                if district is not None:\n",
    "                    row_dict.update({\n",
    "                        'level_2_name': district['NAME'][0],\n",
    "                        'level_2_short_name': district['SOCR'][0],\n",
    "                        'level_2_code': district['CODE'][0],\n",
    "                    })\n",
    "                region = self.find_level_1(code)\n",
    "                if region is not None:\n",
    "                    row_dict.update({\n",
    "                        'level_1_name': region['NAME'][0],\n",
    "                        'level_1_short_name': region['SOCR'][0],\n",
    "                        'level_1_code': region['CODE'][0],\n",
    "                    })\n",
    "                homes = self.find_level_6(row['CODE'])\n",
    "                if homes is not None:\n",
    "                    \n",
    "                    row_dict.update(homes)\n",
    "                self.streets_list_dict.append(\n",
    "                    {\n",
    "                        'index': index,\n",
    "                        'row': row_dict\n",
    "                    }\n",
    "                )\n",
    "            except:\n",
    "                print('Except')\n",
    "                continue\n",
    "        self.streets_df = pd.DataFrame(\n",
    "            [row['row'] for row in self.streets_list_dict],\n",
    "            [index['index'] for index in self.streets_list_dict]\n",
    "        )\n",
    "        self.streets_list_dict.clear()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "run = KladrFinder(kladr, streets, homes, short_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate 0.15152892687213987 %\n",
      "calculate 0.30305785374427974 %\n"
     ]
    }
   ],
   "source": [
    "run.calculate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.create_yandex_data()\n",
    "save_to_csv(run.yandex_addresses, FIND_REGION+'_region.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
