{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to Pandas DataFrame\n",
    "Для того что бы быстрее взаимодействовать с данными переводим их в DataFrame а также сохраняем в бинарном виде через модуль Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(data, file:str):\n",
    "    with open(file, 'wb') as data_file:\n",
    "        pickle.dump(data, data_file)\n",
    "\n",
    "def load_pickle(file):\n",
    "    with open(file, 'rb') as data_file:\n",
    "        return pickle.load(data_file)\n",
    "    \n",
    "def save_to_csv(data, file_name):\n",
    "    data.to_csv(file_name, encoding='utf-16', sep=';', index=False)\n",
    "            \n",
    "def save_to_xlsx(data, file_name):\n",
    "    label = list(data[0].keys())\n",
    "    pd_frame = pd.DataFrame(\n",
    "        data,\n",
    "        columns=label\n",
    "    )\n",
    "    pd_frame.to_excel(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIND_REGION = '50'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первоначальная работа с dbf файлами. В дальнейшем все dbf файлы преобразуются в бинарный формат. Обязательно нужны файлы \"КЛАДР\" в директории data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dbfread import DBF\n",
    "\n",
    "ALTNAMES = DBF('data/ALTNAMES.dbf')\n",
    "DOMA = DBF('data/DOMA.dbf')\n",
    "KLADR = DBF('data/KLADR.dbf')\n",
    "SOCRBASE = DBF('data/SOCRBASE.dbf')\n",
    "STREET = DBF('data/STREET.dbf')\n",
    "NAMEMAP = DBF('data/NAMEMAP.dbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "kladr = pd.DataFrame(iter(KLADR))\n",
    "streets = pd.DataFrame(iter(STREET))\n",
    "homes = pd.DataFrame(iter(DOMA))\n",
    "short_names = pd.DataFrame(iter(SOCRBASE))\n",
    "altnames = pd.DataFrame(iter(ALTNAMES))\n",
    "namemap = pd.DataFrame(iter(NAMEMAP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При этом сразу фильтруем только актуальные адреса, заканчивающиеся на '00'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp_1 = '^'+FIND_REGION+'\\d*00$'\n",
    "regexp_2 = '^'+FIND_REGION+'\\d*'\n",
    "\n",
    "first_kladr = kladr[kladr['CODE'].str.contains(regexp_1)]\n",
    "first_streets = streets[streets['CODE'].str.contains(regexp_1)]\n",
    "first_homes = homes[homes['CODE'].str.contains(regexp_2)]\n",
    "first_altnames = altnames[altnames['NEWCODE'].str.contains(regexp_2)]\n",
    "first_namemap = namemap[namemap['CODE'].str.contains(regexp_2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(first_kladr, 'data/'+FIND_REGION+'_region_kladr.pkl')\n",
    "save_pickle(first_streets, 'data/'+FIND_REGION+'_region_streets.pkl')\n",
    "save_pickle(first_homes, 'data/'+FIND_REGION+'_region_homes.pkl')\n",
    "save_pickle(first_altnames, 'data/'+FIND_REGION+'_region_altnames.pkl')\n",
    "save_pickle(first_namemap, 'data/'+FIND_REGION+'_region_namemap.pkl')\n",
    "save_pickle(short_names, 'data/short_names.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем DataFrame\n",
    "Уже работает с бинарным форматом (это ускоряет работы при отладке)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "kladr:pd.DataFrame = load_pickle('data/'+FIND_REGION+'_region_kladr.pkl')\n",
    "streets:pd.DataFrame = load_pickle('data/'+FIND_REGION+'_region_streets.pkl')\n",
    "homes:pd.DataFrame = load_pickle('data/'+FIND_REGION+'_region_homes.pkl')\n",
    "short_names:pd.DataFrame = load_pickle('data/short_names.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание самого класса и всего функционала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import NaN\n",
    "from pandas import isnull\n",
    "\n",
    "\n",
    "class KladrFinder():\n",
    "    def __init__(\n",
    "            self,\n",
    "            kladr: pd.DataFrame,\n",
    "            streets: pd.DataFrame,\n",
    "            homes: pd.DataFrame,\n",
    "            short_names: pd.DataFrame,\n",
    "            region=31\n",
    "        ) -> None:\n",
    "        self.kladr = kladr\n",
    "        self.streets =streets\n",
    "        self.homes = homes\n",
    "        self.short_names = short_names\n",
    "        self.region = region\n",
    "        self.filename_save_df = 'data/'+str(self.region)+'_region_df.pkl'\n",
    "        \n",
    "        street_df_columns =  [\n",
    "            'level_1_name',\n",
    "            'level_1_short_name',\n",
    "            'level_1_code',\n",
    "            \n",
    "            'level_2_name',\n",
    "            'level_2_short_name',\n",
    "            'level_2_code',\n",
    "            \n",
    "            'level_3_name',\n",
    "            'level_3_short_name',\n",
    "            'level_3_code',\n",
    "            \n",
    "            'level_4_name',\n",
    "            'level_4_short_name',\n",
    "            'level_4_code',\n",
    "            \n",
    "            'level_5_name',\n",
    "            'level_5_short_name',\n",
    "            'level_5_code',\n",
    "            \n",
    "            'level_6_name',\n",
    "            'level_6_short_name',\n",
    "        ] \n",
    "        self.streets_df = pd.DataFrame(columns=street_df_columns, )\n",
    "         \n",
    "        self.streets_list_dict = []\n",
    "         \n",
    "        self.anomaly = []   \n",
    "        \n",
    "        if os.path.isfile(self.filename_save_df):\n",
    "            self.streets_df = self.load_df()\n",
    "        else:\n",
    "            self.calculate()\n",
    "            \n",
    "    def add_anomaly(self, message):\n",
    "        self.anomaly.append(message)\n",
    "                \n",
    "    def load_df(self):\n",
    "        with open(self.filename_save_df, 'rb') as data_file:\n",
    "            return pickle.load(data_file)\n",
    "        \n",
    "    def save_df(self):\n",
    "        with open(self.filename_save_df, 'wb') as data_file:\n",
    "            pickle.dump(self.streets_df, data_file)\n",
    "\n",
    "    def find_level_1(self, code):\n",
    "        new_code = code[:2]+('0'*11)\n",
    "        return self.find_kladr_for_code(new_code)\n",
    "    \n",
    "    def find_level_2(self, code):\n",
    "        if (code[2:5] == '000'):\n",
    "            return None\n",
    "        new_code = code[:5]+('0'*8)\n",
    "        return self.find_kladr_for_code(new_code)\n",
    "    \n",
    "    def find_level_3(self, code):\n",
    "        if (code[5:8] == '000'):\n",
    "            return None       \n",
    "        new_code = code[:8]+('0'*5)\n",
    "        return self.find_kladr_for_code(new_code)\n",
    "    \n",
    "    def find_level_4(self, code:str):\n",
    "        if (code[8:11] == '000'):\n",
    "            return None       \n",
    "        new_code = code[:11]+('0'*2)\n",
    "        return self.find_kladr_for_code(new_code)\n",
    "        \n",
    "    def find_level_6(self, code):\n",
    "        return self.find_home_for_code(code)   \n",
    "    \n",
    "    def find_kladr_for_code(self, code:str):\n",
    "        kladr_list = self.kladr[self.kladr['CODE'].str.contains(code)]\n",
    "        kladr_list = kladr_list.reset_index(drop=True)\n",
    "        return kladr_list\n",
    "\n",
    "    def find_home_for_code(self, code:str):\n",
    "        regexp = r'^'+code+'\\d*'\n",
    "        homes_df = self.homes[self.homes['CODE'].str.contains(regexp)]\n",
    "        names = []\n",
    "        short_name = 'ДОМ'        \n",
    "        for index, row in homes_df.iterrows():\n",
    "            temp = row['NAME'].split(',')\n",
    "            for i in temp:\n",
    "                names.append(i)\n",
    "        return {\n",
    "            'level_6_name': names,\n",
    "            'level_6_short_name': short_name\n",
    "        }\n",
    "    \n",
    "    def to_long_name(self, short_name):\n",
    "        try:\n",
    "            df = self.short_names\n",
    "            line = df[df['SCNAME'] == short_name]['SOCRNAME'].iat[0]        \n",
    "            return line\n",
    "        except:\n",
    "            a = 0\n",
    "\n",
    "    \n",
    "    def create_yandex_data(self):       \n",
    "        df = self.streets_df\n",
    "        short_data_list = [] \n",
    "        long_data_list = []\n",
    "        index_length = len(df.index)\n",
    "        cnt = 0       \n",
    "        for index in df.index:\n",
    "            cnt +=1\n",
    "            if cnt % 1000 == 0:\n",
    "                print('calculate', (cnt/index_length)*100, '%')\n",
    "            homes = df['level_6_name'][index]\n",
    "            for home in homes:\n",
    "                text_levels_short = []\n",
    "                text_levels_long = []\n",
    "            \n",
    "                if 'level_1_name' in df.columns:\n",
    "                    if not pd.isnull(df['level_1_name'][index]):\n",
    "                        text_levels_short.append(' '.join([df['level_1_name'][index], df['level_1_short_name'][index]]))\n",
    "                        text_levels_long.append(' '.join([str(df['level_1_name'][index]), str(self.to_long_name(df['level_1_short_name'][index]))]))\n",
    "                if 'level_2_name' in df.columns:\n",
    "                    if not pd.isnull(df['level_2_name'][index]):\n",
    "                        text_levels_short.append(' '.join([str(df['level_2_name'][index]), str(df['level_2_short_name'][index])]))\n",
    "                        text_levels_long.append(' '.join([str(df['level_2_name'][index]), str(self.to_long_name(df['level_2_short_name'][index]))]))\n",
    "                if 'level_3_name' in df.columns:\n",
    "                    if not pd.isnull(df['level_3_name'][index]):\n",
    "                        text_levels_short.append(' '.join([str(df['level_3_short_name'][index]), str(df['level_3_name'][index])]))\n",
    "                        text_levels_long.append(' '.join([str(self.to_long_name(df['level_3_short_name'][index])), str(df['level_3_name'][index])]))\n",
    "                if 'level_4_name' in df.columns:\n",
    "                    if not pd.isnull(df['level_4_name'][index]):\n",
    "                        text_levels_short.append(' '.join([str(df['level_4_short_name'][index]), str(df['level_4_name'][index])]))\n",
    "                        text_levels_long.append(' '.join([str(self.to_long_name(df['level_4_short_name'][index])), str(df['level_4_name'][index])]))\n",
    "                if 'level_5_name' in self.streets_df.columns:\n",
    "                    if not pd.isnull(df['level_5_name'][index]):\n",
    "                        text_levels_short.append(' '.join([str(df['level_5_name'][index]), str(df['level_5_short_name'][index])]))\n",
    "                        text_levels_long.append(' '.join([str(df['level_5_name'][index]), str(self.to_long_name(df['level_5_short_name'][index]))]))\n",
    "                        \n",
    "                row_dict_short = ', '.join(text_levels_short)\n",
    "                row_dict_short = ' '.join([row_dict_short, home])\n",
    "                short_data_list.append(row_dict_short)\n",
    "                \n",
    "                row_dict_long = ', '.join(text_levels_long)\n",
    "                row_dict_long = ' '.join([row_dict_long, home])\n",
    "                long_data_list.append(row_dict_long)\n",
    "                \n",
    "        self.yandex_addresses_short = pd.DataFrame(short_data_list, columns=['name'])\n",
    "        self.yandex_addresses_long = pd.DataFrame(long_data_list, columns=['name'])\n",
    "    \n",
    "    def create_google_data(self):       \n",
    "        df = self.streets_df\n",
    "        short_data_list = [] \n",
    "        long_data_list = []\n",
    "        index_length = len(df.index)\n",
    "        cnt = 0       \n",
    "        for index in df.index:\n",
    "            cnt +=1\n",
    "            if cnt % 100 == 0:\n",
    "                print('calculate', (cnt/index_length)*100, '%')\n",
    "            homes = df['level_6_name'][index]\n",
    "            for home in homes:\n",
    "                text_levels_short = []\n",
    "                text_levels_long = []\n",
    "                \n",
    "                if 'level_5_name' in self.streets_df.columns:\n",
    "                    if not pd.isnull(df['level_5_name'][index]):\n",
    "                        text_levels_short.append(' '.join([str(df['level_5_name'][index]), str(df['level_5_short_name'][index])]))\n",
    "                        text_levels_long.append(' '.join([str(df['level_5_name'][index]), str(self.to_long_name(df['level_5_short_name'][index]))]))  \n",
    "                text_levels_short.append(home)\n",
    "                text_levels_long.append(home)\n",
    "                if 'level_1_name' in df.columns:\n",
    "                    if not pd.isnull(df['level_1_name'][index]):\n",
    "                        text_levels_short.append(' '.join([str(df['level_1_name'][index]), str(df['level_1_short_name'][index])]))\n",
    "                        text_levels_long.append(' '.join([str(df['level_1_name'][index]), str(self.to_long_name(df['level_1_short_name'][index]))]))\n",
    "                if 'level_2_name' in df.columns:\n",
    "                    if not pd.isnull(df['level_2_name'][index]):\n",
    "                        text_levels_short.append(' '.join([str(df['level_2_name'][index]), str(df['level_2_short_name'][index])]))\n",
    "                        text_levels_long.append(' '.join([str(df['level_2_name'][index]), str(self.to_long_name(df['level_2_short_name'][index]))]))\n",
    "                if 'level_3_name' in df.columns:\n",
    "                    if not pd.isnull(df['level_3_name'][index]):\n",
    "                        text_levels_short.append(' '.join([str(df['level_3_short_name'][index]), str(df['level_3_name'][index])]))\n",
    "                        text_levels_long.append(' '.join([str(self.to_long_name(df['level_3_short_name'][index])), str(df['level_3_name'][index])]))\n",
    "                if 'level_4_name' in df.columns:\n",
    "                    if not pd.isnull(df['level_4_name'][index]):\n",
    "                        text_levels_short.append(' '.join([str(df['level_4_short_name'][index]), str(df['level_4_name'][index])]))\n",
    "                        text_levels_long.append(' '.join([str(self.to_long_name(df['level_4_short_name'][index])), str(df['level_4_name'][index])]))\n",
    "                \n",
    "                text_levels_short.append('Россия')                        \n",
    "                row_dict_short = ', '.join(text_levels_short)\n",
    "                short_data_list.append(row_dict_short)\n",
    "                \n",
    "                text_levels_long.append('Россия')\n",
    "                row_dict_long = ', '.join(text_levels_long)\n",
    "                long_data_list.append(row_dict_long)\n",
    "                \n",
    "        self.google_addresses_short = pd.DataFrame(short_data_list, columns=['name'])\n",
    "        self.google_addresses_long = pd.DataFrame(long_data_list, columns=['name'])    \n",
    "    \n",
    "    def calculate(self):\n",
    "        cnt = 0\n",
    "        for index, row in self.streets.iterrows():\n",
    "            cnt +=1\n",
    "            if cnt % 1000 == 0:\n",
    "                print('calculate', cnt/len(self.streets)*100, '%')\n",
    "            row_dict = {}\n",
    "            try:\n",
    "                row_dict.update({\n",
    "                    'level_5_name': row['NAME'],\n",
    "                    'level_5_short_name': row['SOCR'],\n",
    "                    'level_5_code': row['CODE'],\n",
    "                })\n",
    "                code = row['CODE'][0:-6]+row['CODE'][-2:]\n",
    "                locality = self.find_level_4(code)\n",
    "                if locality is not None:\n",
    "                    row_dict.update({\n",
    "                        'level_4_name': locality['NAME'][0],\n",
    "                        'level_4_short_name': locality['SOCR'][0],\n",
    "                        'level_4_code': locality['CODE'][0],\n",
    "                    })\n",
    "                city = self.find_level_3(code)\n",
    "                if city is not None:\n",
    "                    row_dict.update({\n",
    "                        'level_3_name': city['NAME'][0],\n",
    "                        'level_3_short_name': city['SOCR'][0],\n",
    "                        'level_3_code': city['CODE'][0],\n",
    "                    })\n",
    "                district = self.find_level_2(code)\n",
    "                if district is not None:\n",
    "                    row_dict.update({\n",
    "                        'level_2_name': district['NAME'][0],\n",
    "                        'level_2_short_name': district['SOCR'][0],\n",
    "                        'level_2_code': district['CODE'][0],\n",
    "                    })\n",
    "                region = self.find_level_1(code)\n",
    "                if region is not None:\n",
    "                    row_dict.update({\n",
    "                        'level_1_name': region['NAME'][0],\n",
    "                        'level_1_short_name': region['SOCR'][0],\n",
    "                        'level_1_code': region['CODE'][0],\n",
    "                    })\n",
    "                homes = self.find_level_6(row['CODE'])\n",
    "                if homes is not None:\n",
    "                    \n",
    "                    row_dict.update(homes)\n",
    "                self.streets_list_dict.append(\n",
    "                    {\n",
    "                        'index': index,\n",
    "                        'row': row_dict\n",
    "                    }\n",
    "                )\n",
    "            except:\n",
    "                self.add_anomaly('Except. Index:{}, CODE:{}'.format(index, code))\n",
    "                print('Except. Index:{}, CODE:{}'.format(index, code))\n",
    "                continue\n",
    "        self.streets_df = pd.DataFrame(\n",
    "            [row['row'] for row in self.streets_list_dict],\n",
    "            [index['index'] for index in self.streets_list_dict]\n",
    "        )\n",
    "        self.streets_list_dict.clear()\n",
    "        self.save_df()       \n",
    "\n",
    "run = KladrFinder(kladr, streets, homes, short_names, region=FIND_REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Запуск формирования данных в формате Yandex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate 6.4114893889850615 %\n",
      "calculate 12.822978777970123 %\n",
      "calculate 19.234468166955185 %\n",
      "calculate 25.645957555940246 %\n",
      "calculate 32.0574469449253 %\n",
      "calculate 38.46893633391037 %\n",
      "calculate 44.88042572289543 %\n",
      "calculate 51.29191511188049 %\n",
      "calculate 57.70340450086555 %\n",
      "calculate 64.1148938898506 %\n",
      "calculate 70.52638327883567 %\n",
      "calculate 76.93787266782074 %\n",
      "calculate 83.3493620568058 %\n",
      "calculate 89.76085144579086 %\n",
      "calculate 96.17234083477591 %\n"
     ]
    }
   ],
   "source": [
    "run.create_yandex_data()\n",
    "save_to_csv(run.yandex_addresses_long, FIND_REGION+'_region_yandex_long.csv')\n",
    "save_to_csv(run.yandex_addresses_short, FIND_REGION+'_region_yandex_short.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Запуск формирования данных в формате Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate 0.6411489388985061 %\n",
      "calculate 1.2822978777970122 %\n",
      "calculate 1.9234468166955183 %\n",
      "calculate 2.5645957555940244 %\n",
      "calculate 3.2057446944925307 %\n",
      "calculate 3.8468936333910366 %\n",
      "calculate 4.488042572289543 %\n",
      "calculate 5.129191511188049 %\n",
      "calculate 5.770340450086555 %\n",
      "calculate 6.4114893889850615 %\n",
      "calculate 7.052638327883567 %\n",
      "calculate 7.693787266782073 %\n",
      "calculate 8.33493620568058 %\n",
      "calculate 8.976085144579086 %\n",
      "calculate 9.617234083477593 %\n",
      "calculate 10.258383022376098 %\n",
      "calculate 10.899531961274604 %\n",
      "calculate 11.54068090017311 %\n",
      "calculate 12.181829839071616 %\n",
      "calculate 12.822978777970123 %\n",
      "calculate 13.46412771686863 %\n",
      "calculate 14.105276655767135 %\n",
      "calculate 14.746425594665642 %\n",
      "calculate 15.387574533564147 %\n",
      "calculate 16.02872347246265 %\n",
      "calculate 16.66987241136116 %\n",
      "calculate 17.311021350259665 %\n",
      "calculate 17.952170289158172 %\n",
      "calculate 18.59331922805668 %\n",
      "calculate 19.234468166955185 %\n",
      "calculate 19.875617105853692 %\n",
      "calculate 20.516766044752195 %\n",
      "calculate 21.157914983650702 %\n",
      "calculate 21.79906392254921 %\n",
      "calculate 22.440212861447716 %\n",
      "calculate 23.08136180034622 %\n",
      "calculate 23.722510739244726 %\n",
      "calculate 24.363659678143232 %\n",
      "calculate 25.00480861704174 %\n",
      "calculate 25.645957555940246 %\n",
      "calculate 26.287106494838753 %\n",
      "calculate 26.92825543373726 %\n",
      "calculate 27.569404372635763 %\n",
      "calculate 28.21055331153427 %\n",
      "calculate 28.851702250432776 %\n",
      "calculate 29.492851189331283 %\n",
      "calculate 30.134000128229786 %\n",
      "calculate 30.775149067128293 %\n",
      "calculate 31.4162980060268 %\n",
      "calculate 32.0574469449253 %\n",
      "calculate 32.69859588382381 %\n",
      "calculate 33.33974482272232 %\n",
      "calculate 33.98089376162082 %\n",
      "calculate 34.62204270051933 %\n",
      "calculate 35.26319163941783 %\n",
      "calculate 35.904340578316344 %\n",
      "calculate 36.54548951721485 %\n",
      "calculate 37.18663845611336 %\n",
      "calculate 37.82778739501186 %\n",
      "calculate 38.46893633391037 %\n",
      "calculate 39.110085272808874 %\n",
      "calculate 39.751234211707384 %\n",
      "calculate 40.39238315060589 %\n",
      "calculate 41.03353208950439 %\n",
      "calculate 41.6746810284029 %\n",
      "calculate 42.315829967301404 %\n",
      "calculate 42.95697890619991 %\n",
      "calculate 43.59812784509842 %\n",
      "calculate 44.23927678399692 %\n",
      "calculate 44.88042572289543 %\n",
      "calculate 45.521574661793935 %\n",
      "calculate 46.16272360069244 %\n",
      "calculate 46.80387253959095 %\n",
      "calculate 47.44502147848945 %\n",
      "calculate 48.086170417387955 %\n",
      "calculate 48.727319356286465 %\n",
      "calculate 49.36846829518497 %\n",
      "calculate 50.00961723408348 %\n",
      "calculate 50.65076617298199 %\n",
      "calculate 51.29191511188049 %\n",
      "calculate 51.933064050778995 %\n",
      "calculate 52.574212989677505 %\n",
      "calculate 53.21536192857601 %\n",
      "calculate 53.85651086747452 %\n",
      "calculate 54.49765980637302 %\n",
      "calculate 55.138808745271525 %\n",
      "calculate 55.779957684170036 %\n",
      "calculate 56.42110662306854 %\n",
      "calculate 57.06225556196705 %\n",
      "calculate 57.70340450086555 %\n",
      "calculate 58.344553439764056 %\n",
      "calculate 58.985702378662566 %\n",
      "calculate 59.62685131756107 %\n",
      "calculate 60.26800025645957 %\n",
      "calculate 60.90914919535808 %\n",
      "calculate 61.550298134256586 %\n",
      "calculate 62.19144707315509 %\n",
      "calculate 62.8325960120536 %\n",
      "calculate 63.4737449509521 %\n",
      "calculate 64.1148938898506 %\n",
      "calculate 64.75604282874912 %\n",
      "calculate 65.39719176764763 %\n",
      "calculate 66.03834070654612 %\n",
      "calculate 66.67948964544463 %\n",
      "calculate 67.32063858434314 %\n",
      "calculate 67.96178752324164 %\n",
      "calculate 68.60293646214015 %\n",
      "calculate 69.24408540103866 %\n",
      "calculate 69.88523433993717 %\n",
      "calculate 70.52638327883567 %\n",
      "calculate 71.16753221773418 %\n",
      "calculate 71.80868115663269 %\n",
      "calculate 72.44983009553118 %\n",
      "calculate 73.0909790344297 %\n",
      "calculate 73.7321279733282 %\n",
      "calculate 74.37327691222671 %\n",
      "calculate 75.01442585112522 %\n",
      "calculate 75.65557479002372 %\n",
      "calculate 76.29672372892223 %\n",
      "calculate 76.93787266782074 %\n",
      "calculate 77.57902160671925 %\n",
      "calculate 78.22017054561775 %\n",
      "calculate 78.86131948451626 %\n",
      "calculate 79.50246842341477 %\n",
      "calculate 80.14361736231326 %\n",
      "calculate 80.78476630121177 %\n",
      "calculate 81.42591524011029 %\n",
      "calculate 82.06706417900878 %\n",
      "calculate 82.70821311790729 %\n",
      "calculate 83.3493620568058 %\n",
      "calculate 83.9905109957043 %\n",
      "calculate 84.63165993460281 %\n",
      "calculate 85.27280887350132 %\n",
      "calculate 85.91395781239981 %\n",
      "calculate 86.55510675129833 %\n",
      "calculate 87.19625569019684 %\n",
      "calculate 87.83740462909535 %\n",
      "calculate 88.47855356799384 %\n",
      "calculate 89.11970250689235 %\n",
      "calculate 89.76085144579086 %\n",
      "calculate 90.40200038468936 %\n",
      "calculate 91.04314932358787 %\n",
      "calculate 91.68429826248638 %\n",
      "calculate 92.32544720138488 %\n",
      "calculate 92.96659614028339 %\n",
      "calculate 93.6077450791819 %\n",
      "calculate 94.24889401808039 %\n",
      "calculate 94.8900429569789 %\n",
      "calculate 95.53119189587741 %\n",
      "calculate 96.17234083477591 %\n",
      "calculate 96.81348977367442 %\n",
      "calculate 97.45463871257293 %\n",
      "calculate 98.09578765147144 %\n",
      "calculate 98.73693659036994 %\n",
      "calculate 99.37808552926845 %\n"
     ]
    }
   ],
   "source": [
    "run.create_google_data()\n",
    "save_to_csv(run.google_addresses_long, FIND_REGION+'_region_google_long.csv')\n",
    "save_to_csv(run.google_addresses_short, FIND_REGION+'_region_google_short.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
